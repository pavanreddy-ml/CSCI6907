# Ignore warnings for convergence during model training
import warnings
warnings.filterwarnings("ignore")

# Import necessary libraries
import datetime
import os
from functools import partial
import joblib
import numpy as np
import tensorflow as tf
import math
import matplotlib.pyplot as plt
import seaborn as sns

import sklearn
import numpy as np
import pandas as pd   # Import pandas with an alias for easy reference
import tensorflow as tf
print(tf.__version__)
from sklearn.exceptions import ConvergenceWarning
from sklearn.utils._testing import ignore_warnings
from sklearn.mixture import BayesianGaussianMixture
from functools import partial
from sklearn.preprocessing import OneHotEncoder
import tensorflow_probability as tfp
from sklearn.preprocessing import MinMaxScaler
from sklearn.svm import OneClassSVM

import shutil
from functools import reduce
from tqdm.autonotebook import tqdm

# Install wget if not already installed
import wget

from DataTransformers import *
from GanActivation import *
from GANEvaluation import *
from Models import *
from Utils import *
from CTGan import *

def init_bounded(shape, **kwargs):
    # Check if 'dim' and 'dtype' are provided as keyword arguments
    if 'dim' not in kwargs:
        raise AttributeError('dim not passed as input')
    if 'dtype' not in kwargs:
        raise AttributeError('dtype not passed as input')

    # Retrieve 'dim' and 'dtype' from the provided keyword arguments
    dim = kwargs['dim']
    d_type = kwargs['dtype']

    # Calculate the bound for random initialization based on the dimension 'dim'
    bound = 1 / math.sqrt(dim)

    # Generate random values within the specified range and return as a TensorFlow tensor
    return tf.random.uniform(shape, minval=-bound, maxval=bound, dtype=d_type)

def conditional_loss(cond_info, data, cond, mask):
    """
    Calculate conditional loss using sparse softmax cross-entropy.

    Parameters:
    - cond_info: Information about the conditional vector.
    - data: The generated data.
    - cond: The conditional vector.
    - mask: Binary mask indicating selected columns.

    Returns:
    - c_loss: The calculated conditional loss.

    Calculates the conditional loss using sparse softmax cross-entropy
    for the specified conditional vector, generated data, and binary mask.

    """
    shape = tf.shape(mask)
    c_loss = tf.zeros(shape)

    for item in cond_info:
        data_logsoftmax = data[:, item[0]:item[1]]
        cond_vec = tf.math.argmax(cond[:, item[2]:item[3]], 1)
        loss = tf.reshape(tf.nn.sparse_softmax_cross_entropy_with_logits(
            cond_vec, data_logsoftmax), [-1, 1])
        c_loss = tf.concat(
            [c_loss[:, :item[-1]], loss, c_loss[:, item[-1]+1:]], 1)

    return tf.reduce_sum(c_loss * mask) / tf.cast(shape[0], dtype=tf.float32)

def gradient_penalty(func, real, fake, pac=10, gp_lambda=10.0):
    """
    Calculate the gradient penalty for the specified function.

    Parameters:
    - func: The function for which the gradient penalty is calculated.
    - real: Real data.
    - fake: Generated data.
    - pac: The number of parallel augmentations.
    - gp_lambda: The weight of the gradient penalty.

    Returns:
    - gradient_penalty_value: The calculated gradient penalty value.

    Calculates the gradient penalty for the specified function using real and generated data,
    with the specified number of parallel augmentations and gradient penalty weight.

    """
    alpha = tf.random.uniform([real.shape[0] // pac, 1, 1], 0., 1.)
    alpha = tf.tile(alpha, tf.constant([1, pac, real.shape[1]], tf.int32))
    alpha = tf.reshape(alpha, [-1, real.shape[1]])

    interpolates = alpha * real + ((1 - alpha) * fake)
    with tf.GradientTape() as tape:
        tape.watch(interpolates)
        pred = func(interpolates)
    grad = tape.gradient(pred, [interpolates])[0]
    grad = tf.reshape(grad, tf.constant([-1, pac * real.shape[1]], tf.int32))

    slopes = tf.math.reduce_euclidean_norm(grad, axis=1)
    return tf.reduce_mean((slopes - 1.) ** 2) * gp_lambda

def get_gen_samples_tuple(sample, print_loss=False):
    """
    Generates a tuple of an input sample and a sample generated by the GAN model.

    Args:
    - sample (pd.DataFrame): The input sample to generate a similar sample.
    - print_loss (bool): If True, prints the mean absolute difference between input and generated samples.

    Returns:
    tuple: A tuple containing the input sample and the generated sample.
    """
    noise = model.generate_sample_close_to(sample, num_iterations=NI, learning_rate=LR, verbose=False)
    generated_sample = model.single_sample(1, noise=noise)
    if print_loss:
        generated_sample_np = generated_sample.values.flatten()
        ana_sample_np = sample.values.flatten()
        print(f"Loss for this sample is: {np.mean(np.abs(generated_sample_np - ana_sample_np))}")

    return (sample, generated_sample)

def get_losses(sample_array, loss='mae'):
    """
    Calculate losses between pairs of samples in the given array.

    Args:
    - sample_array (list of tuples): Each tuple contains two samples for comparison.
    - loss (str): Loss metric to compute. Options: 'mae', 'mse', 'rmse', 'cosine'.

    Returns:
    list: List of loss values for each pair of samples.
    """
    l_array = []
    for i in sample_array:
        s1 = i[0].values.flatten()
        s2 = i[1].values.flatten()
        if loss == 'mae':
            l_array.append(np.mean(np.abs(s1 - s2)))
        elif loss == 'mse':
            l_array.append(np.mean(np.square(s1 - s2)))
        elif loss == 'rmse':
            l_array.append(np.sqrt(np.mean(np.square(s1 - s2))))
        elif loss == 'cosine':
            l_array.append(1 - np.dot(s1, s2) / (np.linalg.norm(s1) * np.linalg.norm(s2)))
    return l_array

tf.random.set_seed(1234)
np.random.seed(1234)

# download the dataset
url = "https://raw.githubusercontent.com/google/madi/master/src/madi/datasets/data/anomaly_detection_sample_1577622599.csv"
if os.path.exists("data.csv"):
    print(f"The file exists. No need to download!")
else:
    print(f"The file does not exist.")
    wget.download(url, 'data.csv')


# Data preprocessing

# Read the Dataset

# For google colab uncomment the below line
# df = pd.read_csv("/content/data.csv")

# for local machine uncomment the below line
df = pd.read_csv("data.csv")
df.drop(['dow', 'hod'], axis=1, inplace=True)

ana_df = df[df['class_label'] == 0]
ana_df.drop(['class_label', 'Unnamed: 0'], axis=1, inplace=True)
df_single_class = df[df['class_label'] == 1]
df_single_class.drop(['class_label', 'Unnamed: 0'], axis=1, inplace=True)

# scaler = StandardScaler()
scaler = MinMaxScaler(feature_range=(-1, 1))
scaled_df = pd.DataFrame(scaler.fit_transform(df_single_class), columns=df_single_class.columns)

ana_df = pd.DataFrame(scaler.transform(ana_df), columns=ana_df.columns)

# Baseline model
print("Starting the execution of baseline model")
ocsvm = OneClassSVM(gamma='auto', nu=0.1)
ocsvm.fit(scaled_df)
predictions = ocsvm.predict(pd.concat([ana_df.iloc[:500], scaled_df[:500]]))
predictions[predictions == -1] = 0
baseline_model_accuracy = sklearn.metrics.accuracy_score(predictions, [0]*500 + [1]*500)
print(f"Accuracy for the baseline model OneClass SVM is: {baseline_model_accuracy}")

# AnoGAN model
print("Starting the execution of CT-GAN")
model = CTGANSynthesizer()
model.train(scaled_df, epochs=2)

GANEvaluation().plot_losses(model.get_losses())

# Synthetic data generation using the trained GAN
synthetic_data = model.sample(10000)
# print(synthetic_data.head())

GANEvaluation().plot_kde(data=[scaled_df, synthetic_data])

print("Getting 1 anomaly sample and 1 normal sample for testing..")
ana_sample =  ana_df.head(1)   # Get 1 Anomaly sample for test
nor_sample = scaled_df.head(1)     # Get 1 Normal sample for test

# Get the noise vector that generates a sample closes to the original sample. Compare the samples and get anomaly score (MSE)
print("Get the noise vector that generates a anomaly sample closes to the original sample")
x = model.generate_sample_close_to(ana_sample, learning_rate=2)
generated_sample = model.single_sample(1, noise=x)
mse = tf.reduce_mean(tf.abs(generated_sample - ana_sample))
print(mse)

# Get the noise vector that generates a sample closes to the original sample. Compare the samples and get anomaly score (MSE)
print("Get the noise vector that generates a normal sample closes to the original sample")
x = model.generate_sample_close_to(nor_sample, learning_rate=2)
generated_sample = model.single_sample(1, noise=x)
mse = tf.reduce_mean(tf.abs(generated_sample - nor_sample))
print(mse)

# PARAMS
NI = 1000       # NUM ITERATION FOR NOISE OPTIMIZATION
LR = 0.1        # LEARNING RATE FOR NOISE OPTIMIZATION
N = 50          # NUMS SAMPLE OF EACH CLASS FOR TEST

# Test on N Anomaly Samples
print("Starting generating N anomaly samples...")
ana_sample_arr = []
arr = []
for i in tqdm(range(N)):
    sample =  ana_df.iloc[i:i+1]
    if i%20==0:
        ana_sample_arr.append(get_gen_samples_tuple(sample, print_loss=True))
    else:
        ana_sample_arr.append(get_gen_samples_tuple(sample, print_loss=False))


import random
random.seed(42)
# Test on N Normal Samples
print("Starting generating N normal samples...")
nor_sample_arr = []
arr = []
for i in tqdm(range(N)):
    while True:
        try:
            random_id = random.randint(0, len(df) - 5000)
            sample =  scaled_df.iloc[random_id:random_id+1]
            if i%20==0:
                nor_sample_arr.append(get_gen_samples_tuple(sample, print_loss=True))
            else:
                nor_sample_arr.append(get_gen_samples_tuple(sample, print_loss=False))
            break
        except:
            pass


print("Starting the process of finding the loss...")
measured_loss = 'mse'

ana_sample_arr_x = get_losses(ana_sample_arr, loss=measured_loss)
nor_sample_arr_x = get_losses(nor_sample_arr, loss=measured_loss)


real_labels = ([0] * len(ana_sample_arr)) + ([1] * len(nor_sample_arr))
overall_best_accuracy = 0.0

for base in tqdm(range(10000, 100000000, 1000000)):
#     base = 300000
    best_accuracy = 0.0
    value_of_i = -1
    for i in range(10, 1000):
        thresh = i / (base*1.0)
        ana_sample_arr_class = [0 if x > thresh else 1 for x in ana_sample_arr_x]
        nor_sample_arr_class = [0 if x > thresh else 1 for x in nor_sample_arr_x]
        if sklearn.metrics.accuracy_score(real_labels, ana_sample_arr_class+nor_sample_arr_class) > best_accuracy:
            best_accuracy = sklearn.metrics.accuracy_score(real_labels, ana_sample_arr_class+nor_sample_arr_class)
            value_of_i = i
#         print(f"The threshold is {thresh}, and the accuracy is {sklearn.metrics.accuracy_score(real_labels, ana_sample_arr_class+nor_sample_arr_class)}")

    print(f"The value of i={value_of_i} for best accuracy={best_accuracy} for base={base}")
    if best_accuracy > overall_best_accuracy:
        overall_best_accuracy = best_accuracy
        
print(f"The overall best accuracy for our AnoGAN model is {overall_best_accuracy}")

import seaborn as sns


# Plot the distributions of the anomaly scores for Anomalies and Non-Anomalies
sns.kdeplot(ana_sample_arr_x, shade=True, color="blue", label="Anomalies")  # 'label' will be used for the legend
sns.kdeplot(nor_sample_arr_x, shade=True, color="red", label="Non-Anomalies")

plt.title("Density Distribution of Two Datasets")
plt.xlabel("Value")
plt.ylabel("Density")
plt.legend()
plt.show()